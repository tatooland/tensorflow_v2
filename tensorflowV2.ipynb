{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflowV2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "4G2cnRxt7CjP",
        "vMTlilRcbLPS",
        "AHe_GqhBm1w9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatooland/tensorflow_v2/blob/master/tensorflowV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOwbq4X_MWc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G2cnRxt7CjP",
        "colab_type": "text"
      },
      "source": [
        "##创建简单网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3R_j3vv7Jk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.Input(shape=(784,), name='img')\n",
        "h1 = layers.Dense(32, activation='relu')(inputs)\n",
        "h2 = layers.Dense(32, activation='relu')(h1)\n",
        "outputs = layers.Dense(10, activation='softmax')(h2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, 'mnist_model.png')\n",
        "tf.keras.utils.plot_model(model, 'model_info.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGx9zYzrAlH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=400, epochs=20, validation_split=.2)\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('test loss:', test_scores[0])\n",
        "print('test acc:', test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMTlilRcbLPS",
        "colab_type": "text"
      },
      "source": [
        "##保存模型和序列化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbAEdFuia9Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_save.h5')\n",
        "del model\n",
        "model = tf.keras.models.load_model('model_save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0QdA6DFedpf",
        "colab_type": "text"
      },
      "source": [
        "#使用共享网络创建多个模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGfcG__Pehu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_input = tf.keras.Input(shape=(28, 28, 1), name='img')\n",
        "h1 = layers.Conv2D(16, 3, activation='relu')(encode_input)\n",
        "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
        "h1 = layers.MaxPool2D(3)(h1)\n",
        "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
        "h1 = layers.Conv2D(16, 3, activation='relu')(h1)\n",
        "encode_output = layers.GlobalMaxPool2D(h1)\n",
        "\n",
        "encode_model = tf.keras.Model(inputs=encode_input, outputs=encode_output)\n",
        "encode_model.summary()\n",
        "\n",
        "h2 = layers.Reshape((4, 4, 1))(encode_output)\n",
        "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
        "h2 = layers.Conv2DTranspose(32, 3, activation='relu')(h2)\n",
        "\n",
        "h2 = layers.UpSampling2D(3)(h2)\n",
        "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
        "decode_output = layers.Conv2DTranspose(1, 3, activation='relu')(h2)\n",
        "\n",
        "autoencoder = keras.Model(inputs=encode_input, outputs=decode_output)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnqJSr2Jo2Bh",
        "colab_type": "text"
      },
      "source": [
        "#DCGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYeJ-k78k1XM",
        "colab_type": "text"
      },
      "source": [
        "##generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaw_9Jf8Lk2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator():\n",
        "  #target_shape = (H, W, C) = (128, 128, 3)\n",
        "  \n",
        "  input_val = tf.keras.Input(shape=(100,), name='noise')\n",
        "  input = layers.Dense(4 * 4 * 1024, input_shape=(100,), use_bias=False)(input_val)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "\n",
        "  g = layers.Reshape((4, 4, 1024))(input)\n",
        "\n",
        "  g = layers.Conv2DTranspose(512, 3, strides=(2, 2), use_bias=False, padding='same')(g)\n",
        "  g = layers.BatchNormalization()(g)\n",
        "  g = layers.LeakyReLU()(g)\n",
        "  #assert g.shape() == (None, 8, 8, 512)\n",
        "\n",
        "  g = layers.Conv2DTranspose(256, 3, strides=(2, 2), use_bias=False, padding='same')(g)\n",
        "  g = layers.BatchNormalization()(g)\n",
        "  g = layers.LeakyReLU()(g)\n",
        "  #assert g.shape() == (None, 16, 16, 256)\n",
        "\n",
        "  g = layers.Conv2DTranspose(128, 3, strides=(2, 2), use_bias=False, padding='same')(g)\n",
        "  g = layers.BatchNormalization()(g)\n",
        "  g = layers.LeakyReLU()(g)\n",
        "  #assert g.shape() == (None, 32, 32, 128)\n",
        "\n",
        "  g = layers.Conv2DTranspose(64, 3, strides=(2, 2), use_bias=False, padding='same')(g)\n",
        "  g = layers.BatchNormalization()(g)\n",
        "  g = layers.LeakyReLU()(g)\n",
        "  #assert g.shape() == (None, 64, 64, 64)\n",
        "\n",
        "  output = layers.Conv2DTranspose(3, 3, strides=(2, 2), use_bias=False, activation='tanh', padding='same')(g)\n",
        "  #assert g.shape() == (None, 128, 128, 3)\n",
        "\n",
        "  return tf.keras.Model(inputs=input_val, outputs=output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHe_GqhBm1w9",
        "colab_type": "text"
      },
      "source": [
        "###生成图片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fyZ6eRIm1CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "noise = tf.random.normal([1, 100])\n",
        "g = generator()\n",
        "g_img = g(noise, training=False)\n",
        "print(g_img.shape)\n",
        "plt.imshow(g_img[0, :, :, 0], cmap='gray' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RvHsS31JwrZ",
        "colab_type": "text"
      },
      "source": [
        "##DISCRIMINATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmAusAhJXQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator():\n",
        "  input_val = tf.keras.Input(shape=(128, 128, 3))\n",
        "  input = layers.Conv2D(64, 3, strides=(2, 2), padding='same')(input_val)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "  input = layers.Dropout(.3)(input)\n",
        "  #(64, 64, 64)\n",
        "\n",
        "  input = layers.Conv2D(128, 3, strides=(2, 2), padding='same')(input)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "  input = layers.Dropout(.3)(input)\n",
        "  #(32, 32, 128)\n",
        "\n",
        "  input = layers.Conv2D(256, 3, strides=(2, 2), padding='same')(input)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "  input = layers.Dropout(.3)(input)\n",
        "  #(16, 16, 256)\n",
        "\n",
        "  input = layers.Conv2D(512, 3, strides=(2, 2), padding='same')(input)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "  input = layers.Dropout(.3)(input)\n",
        "  #(8, 8, 512)\n",
        "\n",
        "  input = layers.Conv2D(1024, 3, strides=(2, 2), padding='same')(input)\n",
        "  input = layers.LeakyReLU()(input)\n",
        "  input = layers.Dropout(.3)(input)\n",
        "  #(4, 4, 1024)\n",
        "\n",
        "  input = layers.Flatten()(input)\n",
        "  input = layers.Dense(4*4*1024)(input)\n",
        "  output = layers.Dense(1)(input)\n",
        "\n",
        "  return tf.keras.Model(inputs=input_val, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-vGByOoYFPU",
        "colab_type": "text"
      },
      "source": [
        "##DISCRIMINATOR LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7UOkfavYKPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combined_loss(d_real_output, d_fake_output):\n",
        "  bce = tf.keras.losses.BinaryCrossentropy()\n",
        "  dr_loss = bce(tf.ones(shape=tf.shape(d_real_output), d_real_output)\n",
        "  df_loss = bce(tf.zeros(shape=d_fake_output), d_fake_output)\n",
        "  return dr_loss + df_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpBmkxTh9CX3",
        "colab_type": "text"
      },
      "source": [
        "##GENERATOR LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mptNvzRL9HjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}